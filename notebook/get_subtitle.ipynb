{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/var/pyenv/versions/3.6.1/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/var/pyenv/versions/3.6.1/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import wikitextparser as wtp\n",
    "import re\n",
    "from collections import Counter\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist if len(item) is not 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1385415</td>\n",
       "      <td>アビエチン酸（Abietic acid）は松脂に含まれる主要な刺激性成分で、ロジンを構成する...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3430792</td>\n",
       "      <td>構造的には重篤な造血機能障害を生ずるアミノピリンと同系統であるが、発癌作用のあるニトロソアミ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3430792</td>\n",
       "      <td>心房性の徐脈を伴う急性下壁心筋梗塞（コーニス症候群（英語版））が報告されている。</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3430792</td>\n",
       "      <td>医療用医薬品の添付文書に記載されている重大な副作用は、ショック、皮膚粘膜眼症候群（Steve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3430792</td>\n",
       "      <td>重篤な副作用により、いくつかの国では製造販売が禁止されたが、日本やイタリア、ドイツ、スペイン...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       _id                                           sentence  label\n",
       "0  1385415  アビエチン酸（Abietic acid）は松脂に含まれる主要な刺激性成分で、ロジンを構成する...      0\n",
       "1  3430792  構造的には重篤な造血機能障害を生ずるアミノピリンと同系統であるが、発癌作用のあるニトロソアミ...      0\n",
       "2  3430792           心房性の徐脈を伴う急性下壁心筋梗塞（コーニス症候群（英語版））が報告されている。      0\n",
       "3  3430792  医療用医薬品の添付文書に記載されている重大な副作用は、ショック、皮膚粘膜眼症候群（Steve...      0\n",
       "4  3430792  重篤な副作用により、いくつかの国では製造販売が禁止されたが、日本やイタリア、ドイツ、スペイン...      0"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"../data/train_Youto_sentence.csv\", dtype={'_id': str})\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jasonl(filename):\n",
    "    with open(filename) as f:\n",
    "        return [json.loads(line.rstrip('\\r\\n')) for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_data = read_jasonl(\"../data/jawiki-cirrussearch-dump_of_Compound.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## サブカテゴリ名を取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "heading_list = Counter(flatten([p['heading'] for p in dump_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(\n",
    "    heading_list, orient='index', columns=['count_']\n",
    ").reset_index().rename(columns={'index': 'head'}).sort_values('count_', ascending=False).to_csv(\"../data/head_name_list.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## サブタイトル名を学習データに追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub(text, s):\n",
    "    for i in s:\n",
    "        if isinstance(i, str):\n",
    "            text = text.replace(i, '')\n",
    "        else:\n",
    "            text = text.replace(i.string, '')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(source_text):\n",
    "    clean_text = sub(source_text.contents, source_text.templates)\n",
    "    clean_text = sub(clean_text, source_text.tags())\n",
    "    clean_text = sub(clean_text, source_text.external_links)\n",
    "\n",
    "    clean_text = re.sub(r'\\n|\\t|\\r', '', clean_text)\n",
    "    clean_text = re.sub(r'={2,}.*?={2,}', '', clean_text)\n",
    "    clean_text = re.sub(r'\\[\\[[^\\]]+:.+?\\]\\]', '', clean_text)\n",
    "    clean_text = re.sub(r'\\[\\[[^\\]]+?\\||\\]\\]|\\[\\[', '', clean_text)\n",
    "    clean_text = re.sub(r'\\'{2,}|\\*+|#+', '', clean_text)\n",
    "    clean_text = re.sub(r'<[^>]*?>.*?<\\/[^>]*?>', '', clean_text)\n",
    "    clean_text = re.sub(r'{{.*?}}|{.*?}', '', clean_text)\n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.assign(heading = '')\n",
    "\n",
    "new_train_df = pd.DataFrame()\n",
    "\n",
    "for _id in train._id.unique():\n",
    "    train_article = train.loc[train._id == _id].reset_index(drop=True)\n",
    "    \n",
    "    article = [entry for entry in wiki_data if entry['index']['_id'] == _id][0]\n",
    "    parsed = wtp.parse(article['source_text'])\n",
    "    \n",
    "    for source in parsed.sections[1:]:\n",
    "        m = re.search(r'==+\\s+?([^=]+?)\\s+?==+', source.string)\n",
    "        if m:\n",
    "            heading = m.group(1)\n",
    "        else:\n",
    "            heading = ''\n",
    "\n",
    "        section_text = clean_text(source)\n",
    "        for s in re.findall(r'.*?。', section_text):\n",
    "            m_sentence = difflib.get_close_matches(s, train_article.sentence.values, n=1)\n",
    "            if len(m_sentence) > 0 and len(heading) > 0:\n",
    "                train_article.loc[train_article.sentence == m_sentence[0], ['heading']] = \\\n",
    "                    train_article.loc[train_article.sentence == m_sentence[0], ['heading']] + ' ' + heading\n",
    "                #train_article.loc[train_article.sentence == m_sentence[0], 'heading'] = heading\n",
    "\n",
    "    if len(train_article.loc[train_article.heading != '']) is 0:\n",
    "        train_article.loc[train_article.heading == '', ['heading']] = 'NO_SUBTITLE'\n",
    "    else :\n",
    "        train_article.loc[0:train_article[train_article.heading != ''].index[0], ['heading']] = 'NO_SUBTITLE'\n",
    "        \n",
    "    while len(train_article.loc[train_article.heading == '']) > 0: \n",
    "        train_article.loc[train_article.heading == '', ['heading']] = \\\n",
    "            train_article.loc[train_article.loc[train_article.heading == '', ['heading']].index - 1, 'heading'].values[0]\n",
    "        \n",
    "    new_train_df = new_train_df.append(train_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df.to_csv(\"../data/train_Youto_sentence_and_heading.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
